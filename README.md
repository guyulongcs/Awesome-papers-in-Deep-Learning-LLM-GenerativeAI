## Awesome papers in Deep Learning, Generative AI, LLM.

## 0_Deep_Learning
* [2012 (NIPS) [CNN] ImageNet Classification with Deep Convolutional Neural Networks](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2012%20%28NIPS%29%20%5BCNN%5D%20ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks.pdf) <br />
* [2014 (JMLR) [Dropout] Dropout - A Simple Way to Prevent Neural Networks from Overfitting](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2014%20%28JMLR%29%20%5BDropout%5D%20Dropout%20-%20A%20Simple%20Way%20to%20Prevent%20Neural%20Networks%20from%20Overfitting.pdf) <br />
* [2015 (Google) (JMLR) [BatchNorm] Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2015%20%28Google%29%20%28JMLR%29%20%5BBatchNorm%5D%20Batch%20Normalization%20-%20Accelerating%20Deep%20Network%20Training%20by%20Reducing%20Internal%20Covariate%20Shift.pdf) <br />
* [2015 (OpenAI) (ICLR) [Adam] Adam - A Method for Stochastic Optimization](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2015%20%28OpenAI%29%20%28ICLR%29%20%5BAdam%5D%20Adam%20-%20A%20Method%20for%20Stochastic%20Optimization.pdf) <br />
* [2016 (CVPR) [ResNet] Deep Residual Learning for Image Recognition](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2016%20%28CVPR%29%20%5BResNet%5D%20Deep%20Residual%20Learning%20for%20Image%20Recognition.pdf) <br />
* [2017 (Arxiv) [LayerNorm] Layer Normalization](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2017%20%28Arxiv%29%20%5BLayerNorm%5D%20Layer%20Normalization.pdf) <br />
* [2017 (Google) (NIPS) [Transformer] Attention Is All You Need](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/0_Deep_Learning/2017%20%28Google%29%20%28NIPS%29%20%5BTransformer%5D%20Attention%20Is%20All%20You%20Need.pdf) <br />

## 1_LLM
* [2013 (Google) (NIPS) [Word2vec] Distributed Representations of Words and Phrases and their Compositionality](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2013%20%28Google%29%20%28NIPS%29%20%5BWord2vec%5D%20Distributed%20Representations%20of%20Words%20and%20Phrases%20and%20their%20Compositionality.pdf) <br />
* [2014 (Google) (NIPS) [Seq2Seq] Sequence to Sequence Learning with Neural Networks](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2014%20%28Google%29%20%28NIPS%29%20%5BSeq2Seq%5D%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.pdf) <br />
* [2017 (Google) (NIPS) [Transformer] Attention Is All You Need](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2017%20%28Google%29%20%28NIPS%29%20%5BTransformer%5D%20Attention%20Is%20All%20You%20Need.pdf) <br />
* [2017 (OpenAI) (NIPS) [RLHF] Deep Reinforcement Learning from Human Preferences](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2017%20%28OpenAI%29%20%28NIPS%29%20%5BRLHF%5D%20Deep%20Reinforcement%20Learning%20from%20Human%20Preferences.pdf) <br />
* [2018 (OpenAI) (Arxiv) [GPT] Improving Language Understanding by Generative Pre-Training](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2018%20%28OpenAI%29%20%28Arxiv%29%20%5BGPT%5D%20Improving%20Language%20Understanding%20by%20Generative%20Pre-Training.pdf) <br />
* [2019 (Google) (NAACL) [Bert] BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2019%20%28Google%29%20%28NAACL%29%20%5BBert%5D%20BERT%20-%20Pre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding.pdf) <br />
* [2019 (OpenAI) (Arxiv) [GPT2] Language Models are Unsupervised Multitask Learners](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2019%20%28OpenAI%29%20%28Arxiv%29%20%5BGPT2%5D%20Language%20Models%20are%20Unsupervised%20Multitask%20Learners.pdf) <br />
* [2020 (Arxiv) Scaling Laws for Neural Language Models](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2020%20%28Arxiv%29%20Scaling%20Laws%20for%20Neural%20Language%20Models.pdf) <br />
* [2020 (OpenAI) (Arxiv) [GPT3] Language Models are Few-Shot Learners](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2020%20%28OpenAI%29%20%28Arxiv%29%20%5BGPT3%5D%20Language%20Models%20are%20Few-Shot%20Learners.pdf) <br />
* [2022 (Google) (JMLR) [SwitchTransfomers] Switch Transformers - Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2022%20%28Google%29%20%28JMLR%29%20%5BSwitchTransfomers%5D%20Switch%20Transformers%20-%20Scaling%20to%20Trillion%20Parameter%20Models%20with%20Simple%20and%20Efficient%20Sparsity.pdf) <br />
* [2022 (Google) (NIPS) [ChainOfThought] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2022%20%28Google%29%20%28NIPS%29%20%5BChainOfThought%5D%20Chain-of-Thought%20Prompting%20Elicits%20Reasoning%20in%20Large%20Language%20Models.pdf) <br />
* [2022 (Google) (TMLR) [Emergent] Emergent Abilities of Large Language Models](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2022%20%28Google%29%20%28TMLR%29%20%5BEmergent%5D%20Emergent%20Abilities%20of%20Large%20Language%20Models.pdf) <br />
* [2022 (OpenAI) (Arxiv) [InstructGPT] Training language models to follow instructions with human feedback](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2022%20%28OpenAI%29%20%28Arxiv%29%20%5BInstructGPT%5D%20Training%20language%20models%20to%20follow%20instructions%20with%20human%20feedback.pdf) <br />
* [2023 (Meta) (Arxiv) [LLaMA] LLaMA - Open and Efficient Foundation Language Models](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2023%20%28Meta%29%20%28Arxiv%29%20%5BLLaMA%5D%20LLaMA%20-%20Open%20and%20Efficient%20Foundation%20Language%20Models.pdf) <br />
* [2023 (OpenAI) (Arxiv) [GPT4] GPT-4 Technical Report](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/1_LLM/2023%20%28OpenAI%29%20%28Arxiv%29%20%5BGPT4%5D%20GPT-4%20Technical%20Report.pdf) <br />

## 2_CV
* [2014 (ICML) [VAE] Auto-Encoding Variational Bayes](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/2_CV/2014%20%28ICML%29%20%5BVAE%5D%20Auto-Encoding%20Variational%20Bayes.pdf) <br />
* [2014 (NIPS) [GAN] Generative Adversarial Nets](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/2_CV/2014%20%28NIPS%29%20%5BGAN%5D%20Generative%20Adversarial%20Nets.pdf) <br />
* [2017 (NIPS) [VQ-VAE] Neural Discrete Representation Learning](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/2_CV/2017%20%28NIPS%29%20%5BVQ-VAE%5D%20Neural%20Discrete%20Representation%20Learning.pdf) <br />
* [2020 (NIPS) [Diffusion] Denoising Diffusion Probabilistic Models](https://github.com/guyulongcs/Awesome-papers-in-DeepLearning-GenerativeAI/blob/master/2_CV/2020%20%28NIPS%29%20%5BDiffusion%5D%20Denoising%20Diffusion%20Probabilistic%20Models.pdf) <br />
